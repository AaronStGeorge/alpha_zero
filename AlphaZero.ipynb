{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AlphaGo Zero\n",
    "---\n",
    "For this exercise we will implement AlphaZero which is a more generalized form of AlphaGO and train it on a game of \n",
    "connect 4. We will first play against AlphaZero when it has not trained at all then train it for a few epochs then try \n",
    "to beat it again. We will repeat this process a few time so that you can tangably observe the algorithm getting smarter. "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Game Definition\n",
    "---\n",
    "First lets set up the connect 4 game. This part has been done for you. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class board():\n",
    "    def __init__(self):\n",
    "        self.init_board = np.zeros([6,7]).astype(str)\n",
    "        self.init_board[self.init_board == \"0.0\"] = \" \"\n",
    "        self.player = 0\n",
    "        self.current_board = self.init_board\n",
    "    \n",
    "    def drop_piece(self, column):\n",
    "        if self.current_board[0, column] != \" \":\n",
    "            return \"Invalid move\"\n",
    "        else:\n",
    "            row = 0; pos = \" \"\n",
    "            while (pos == \" \"):\n",
    "                if row == 6:\n",
    "                    row += 1\n",
    "                    break\n",
    "                pos = self.current_board[row, column]\n",
    "                row += 1\n",
    "            if self.player == 0:\n",
    "                self.current_board[row-2, column] = \"O\"\n",
    "                self.player = 1\n",
    "            elif self.player == 1:\n",
    "                self.current_board[row-2, column] = \"X\"\n",
    "                self.player = 0\n",
    "    \n",
    "    def check_pieces(self, piece_string):\n",
    "        for row in range(6):\n",
    "                for col in range(7):\n",
    "                    if self.current_board[row, col] != \" \":\n",
    "                        # rows\n",
    "                        try:\n",
    "                            if self.current_board[row, col] == piece_string and self.current_board[row + 1, col] == piece_string and \\\n",
    "                                self.current_board[row + 2, col] == piece_string and self.current_board[row + 3, col] == piece_string:\n",
    "                                #print(\"row\")\n",
    "                                return True\n",
    "                        except IndexError:\n",
    "                            next\n",
    "                        # columns\n",
    "                        try:\n",
    "                            if self.current_board[row, col] == piece_string and self.current_board[row, col + 1] == piece_string and \\\n",
    "                                self.current_board[row, col + 2] == piece_string and self.current_board[row, col + 3] == piece_string:\n",
    "                                #print(\"col\")\n",
    "                                return True\n",
    "                        except IndexError:\n",
    "                            next\n",
    "                        # \\ diagonal\n",
    "                        try:\n",
    "                            if self.current_board[row, col] == piece_string and self.current_board[row + 1, col + 1] == piece_string and \\\n",
    "                                self.current_board[row + 2, col + 2] == piece_string and self.current_board[row + 3, col + 3] == piece_string:\n",
    "                                #print(\"\\\\\")\n",
    "                                return True\n",
    "                        except IndexError:\n",
    "                            next\n",
    "                        # / diagonal\n",
    "                        try:\n",
    "                            if self.current_board[row, col] == piece_string and self.current_board[row + 1, col - 1] == piece_string and \\\n",
    "                                self.current_board[row + 2, col - 2] == piece_string and self.current_board[row + 3, col - 3] == piece_string\\\n",
    "                                and (col-3) >= 0:\n",
    "                                #print(\"/\")\n",
    "                                return True\n",
    "                        except IndexError:\n",
    "                            next\n",
    "    def check_winner(self):\n",
    "        if self.player == 1:\n",
    "            self.check_pieces(\"O\")\n",
    "            \n",
    "        if self.player == 0:\n",
    "            self.check_pieces(\"X\")\n",
    "            \n",
    "    def actions(self): # returns all possible moves\n",
    "        acts = []\n",
    "        for col in range(7):\n",
    "            if self.current_board[0, col] == \" \":\n",
    "                acts.append(col)\n",
    "        return acts\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. One Network Two Heads\n",
    "---\n",
    "Next lets implement the Neural Network. Recall that AlphaGo Zero uses Convolutional \n",
    "ResNet architecture with two heads. One that outputs a probability distribution over all possible moves $(p)$ and another that \n",
    "outputs a single scalar value $(v)$ representing the value of the current state. Because we have two heads we need to create a \n",
    "custom loos function.   \n",
    "\n",
    "The neural network is defined as:  \n",
    "$$f_\\theta (s) = (\\mathbf{p,v})$$  \n",
    "The loss function is defined as:  \n",
    "$$l = (z - \\mathbf{v})^2 - \\pi^T log(\\mathbf{p}) + c||\\theta||^2$$  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import numpy as np\n",
    "\n",
    "class board_data(Dataset):\n",
    "    def __init__(self, dataset): # dataset = np.array of (s, p, v)\n",
    "        self.X = dataset[:,0]\n",
    "        self.y_p, self.y_v = dataset[:,1], dataset[:,2]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return np.int64(self.X[idx].transpose(2,0,1)), self.y_p[idx], self.y_v[idx]\n",
    "    \n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the first part of the ResNet where we define the convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = 7\n",
    "        self.conv1 = nn.Conv2d(3, 128, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.view(-1, 3, 6, 7)  # batch_size x channels x board_x x board_y\n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        return s\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Here is where we define the Residual blocks\n",
    "    \"\"\"\n",
    "    def __init__(self, inplanes=128, planes=128, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This is where the NN splits into two heads\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "        \"\"\"\n",
    "        Value Head\n",
    "        \"\"\"\n",
    "        self.conv = nn.Conv2d(128, 3, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(3)\n",
    "        self.fc1 = nn.Linear(3*6*7, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Policy Head\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(128, 32, kernel_size=1) # policy head\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc = nn.Linear(6*7*32, 7)\n",
    "    \n",
    "    def forward(self,s):\n",
    "        \"\"\"\n",
    "        Value Head\n",
    "        \"\"\"\n",
    "        v = F.relu(self.bn(self.conv(s)))\n",
    "        v = v.view(-1, 3*6*7)  # batch_size X channel X height X width\n",
    "        v = F.relu(self.fc1(v))\n",
    "        v = torch.tanh(self.fc2(v))\n",
    "        \n",
    "        \"\"\"\n",
    "        Policy Head\n",
    "        \"\"\"\n",
    "        p = F.relu(self.bn1(self.conv1(s))) # policy head\n",
    "        p = p.view(-1, 6*7*32)\n",
    "        p = self.fc(p)\n",
    "        p = self.logsoftmax(p).exp()\n",
    "        return p, v\n",
    "\n",
    "class ConnectNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Here we bring the ResNet and the two head together\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConnectNet, self).__init__()\n",
    "        self.conv = ConvBlock()\n",
    "        for block in range(10):\n",
    "            setattr(self, \"res_%i\" % block,ResBlock())\n",
    "        self.outblock = OutBlock()\n",
    "    \n",
    "    def forward(self,s):\n",
    "        s = self.conv(s)\n",
    "        for block in range(10):\n",
    "            s = getattr(self, \"res_%i\" % block)(s)\n",
    "        s = self.outblock(s)\n",
    "        return s\n",
    "    \n",
    "class AlphaLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Here we define the loss function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AlphaLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_value, value, y_policy, policy):\n",
    "        value_error = (value - y_value) ** 2\n",
    "        policy_error = torch.sum((-policy * (1e-8 + y_policy.float()).float().log()), 1)\n",
    "        \n",
    "        total_error = (value_error.view(-1).float() + policy_error)\n",
    "        return total_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Make the Board Accessible to the NN\n",
    "---\n",
    "The game is encoded in a 6 x 7 matrix. We need to make this into a data structure that can be transformed into a tensor \n",
    "that our NN will understand. Our NN takes a tensor of 6 x 7 x 3. The first two channels indicate each players pieces on \n",
    "the board and the third indicates whose turn it is. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def encode_board(board):\n",
    "    \"\"\"\n",
    "    Take board representation and turns in into 3 matrices so it can be easily converted into a tensor. \n",
    "    :param board: 6 x 7 matrix of strings\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    board_state = board.current_board\n",
    "    encoded = np.zeros([6,7,3]).astype(int)\n",
    "    encoder_dict = {\"O\":0, \"X\":1}\n",
    "    for row in range(6):\n",
    "        for col in range(7):\n",
    "            if board_state[row,col] != \" \":\n",
    "                encoded[row, col, encoder_dict[board_state[row,col]]] = 1\n",
    "    if board.player == 1:\n",
    "        encoded[:,:,2] = 1 # player to move\n",
    "    return encoded\n",
    "\n",
    "def decode_board(encoded):\n",
    "    \"\"\"\n",
    "    DO WE NEED THIS? \n",
    "    :param encoded: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    decoded = np.zeros([6,7]).astype(str)\n",
    "    decoded[decoded == \"0.0\"] = \" \"\n",
    "    decoder_dict = {0:\"O\", 1:\"X\"}\n",
    "    for row in range(6):\n",
    "        for col in range(7):\n",
    "            for k in range(2):\n",
    "                if encoded[row, col, k] == 1:\n",
    "                    decoded[row, col] = decoder_dict[k]\n",
    "    cboard = board()\n",
    "    cboard.current_board = decoded\n",
    "    cboard.player = encoded[0,0,2]\n",
    "    return cboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Monte Carlo Tree Search (MCTS)\n",
    "---\n",
    "Now for the guts of the algorithm. To determine the best move(edge) $a$ at each state(node) $s$ we do a MCTS using the neural network \n",
    "to guide our exploration. During exploration, we chose the max over all possible actions $A$.  \n",
    "\n",
    "$$a = \\max_{a \\in A} (Q + U)$$  \n",
    "In this equation $Q$ is our state-action value and represents exploitation. The Q term represents the exploration term. \n",
    "If we expand $U$ we get the following:  \n",
    "$$Q + c_{punct} P(s,a) \\frac{\\sqrt{\\sum_b N(s,b)}}{1 + N(s,a)}$$  \n",
    "$c_{punct}$ is a constant that controls exploration  \n",
    "$$P(s,a)$$ is the prior probability of choosing action $a$ from policy $p$ given by $f_\\theta (s)$   \n",
    "$\\sum_b N(s,b)$ is the parent node visit count  \n",
    "$$N(s,a)$$ is the number of visits to the current node. \n",
    "\n",
    "Recall that each node in the tree represents a state $s$. Each edge represents an action $a$ that we can take from that \n",
    "state "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class UCTNode():\n",
    "    def __init__(self, game, move, parent=None):\n",
    "        self.game = game # state s\n",
    "        self.move = move # action index\n",
    "        self.is_expanded = False\n",
    "        self.parent = parent  \n",
    "        self.children = {}\n",
    "        self.child_priors = np.zeros([7], dtype=np.float32)\n",
    "        self.child_total_value = np.zeros([7], dtype=np.float32)\n",
    "        self.child_number_visits = np.zeros([7], dtype=np.float32)\n",
    "        self.action_idxes = []\n",
    "        \n",
    "    @property\n",
    "    def number_visits(self):\n",
    "        return self.parent.child_number_visits[self.move]\n",
    "\n",
    "    @number_visits.setter\n",
    "    def number_visits(self, value):\n",
    "        self.parent.child_number_visits[self.move] = value\n",
    "    \n",
    "    @property\n",
    "    def total_value(self):\n",
    "        return self.parent.child_total_value[self.move]\n",
    "    \n",
    "    @total_value.setter\n",
    "    def total_value(self, value):\n",
    "        self.parent.child_total_value[self.move] = value\n",
    "    \n",
    "    def child_Q(self):\n",
    "        return self.child_total_value / (1 + self.child_number_visits)\n",
    "    \n",
    "    def child_U(self):\n",
    "        return np.sqrt(self.number_visits) * (\n",
    "            abs(self.child_priors) / (1 + self.child_number_visits))\n",
    "    \n",
    "    def best_child(self):\n",
    "        if self.action_idxes != []:\n",
    "            bestmove = self.child_Q() + self.child_U()\n",
    "            bestmove = self.action_idxes[np.argmax(bestmove[self.action_idxes])]\n",
    "        else:\n",
    "            bestmove = np.argmax(self.child_Q() + self.child_U())\n",
    "        return bestmove\n",
    "    \n",
    "    def select_leaf(self):\n",
    "        current = self\n",
    "        while current.is_expanded:\n",
    "          best_move = current.best_child()\n",
    "          current = current.maybe_add_child(best_move)\n",
    "        return current\n",
    "    \n",
    "    def add_dirichlet_noise(self, action_idxs, child_priors):\n",
    "        \"\"\"\n",
    "        Adds dirichlet noise to priors for actions from root node to ensure exploration.\n",
    "        :param action_idxs: \n",
    "        :param child_priors: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # select only legal moves entries in child_priors array\n",
    "        valid_child_priors = child_priors[action_idxs] \n",
    "        valid_child_priors = 0.75*valid_child_priors + 0.25*np.random.dirichlet(np.zeros([len(valid_child_priors)], \\\n",
    "                                                                                          dtype=np.float32)+192)\n",
    "        child_priors[action_idxs] = valid_child_priors\n",
    "        return child_priors\n",
    "    \n",
    "    def expand(self, child_priors):\n",
    "        self.is_expanded = True\n",
    "        action_idxs = self.game.actions()\n",
    "        \n",
    "        # c_p is set to child priors because c_p = 1 for now\n",
    "        c_p = child_priors\n",
    "        \n",
    "        # if there are no legal actions do not expand node\n",
    "        if action_idxs == []:\n",
    "            self.is_expanded = False\n",
    "        self.action_idxes = action_idxs\n",
    "        \n",
    "        # mask all illegal actions\n",
    "        for i in range(len(child_priors)):\n",
    "            if i not in action_idxs:\n",
    "                c_p[i] = 0.000000000\n",
    "                        \n",
    "        # add dirichlet noise to child_priors in root node\n",
    "        if self.parent.parent == None: \n",
    "            c_p = self.add_dirichlet_noise(action_idxs,c_p)\n",
    "        self.child_priors = c_p\n",
    "    \n",
    "    def decode_n_move_pieces(self,board,move):\n",
    "        board.drop_piece(move)\n",
    "        return board\n",
    "            \n",
    "    def maybe_add_child(self, move):\n",
    "        if move not in self.children:\n",
    "            copy_board = copy.deepcopy(self.game) # make copy of board\n",
    "            copy_board = self.decode_n_move_pieces(copy_board,move)\n",
    "            self.children[move] = UCTNode(copy_board, move, parent=self)\n",
    "        return self.children[move]\n",
    "    \n",
    "    def backup(self, value_estimate: float):\n",
    "        current = self\n",
    "        while current.parent is not None:\n",
    "            current.number_visits += 1\n",
    "            if current.game.player == 1: # same as current.parent.game.player = 0\n",
    "                current.total_value += (1*value_estimate) # value estimate +1 = O wins\n",
    "            elif current.game.player == 0: # same as current.parent.game.player = 1\n",
    "                current.total_value += (-1*value_estimate)\n",
    "            current = current.parent\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}